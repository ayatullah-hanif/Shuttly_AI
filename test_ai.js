// test-ai.js
const { handleConversation } = require('./server/services/llama');
const { executeTool } = require('./server/controllers/tools');

async function testAI() {
  console.log('ðŸ¤– Testing Llama AI...\n');

  // Tool executor
  const toolExecutor = async (toolName, args) => {
    console.log(`ðŸ”§ Calling tool: ${toolName}`);
    return await executeTool(toolName, args);
  };

  // Test queries
  const queries = [
    'Hello',
    'How much from Ojota to Oshodi?',
    'Are there buses at Maryland?',
    'Show me cities',
    'I want to make a complaint about the dirty bus'
  ];

  for (const query of queries) {
    console.log(`\nðŸ‘¤ User: ${query}`);
    console.log('â”€'.repeat(50));

    const result = await handleConversation(query, [], toolExecutor);

    if (result.success) {
      console.log(`ðŸ¤– Bot: ${result.response}\n`);
    } else {
      console.log(`âŒ Error: ${result.response}\n`);
    }

    // Wait a bit between requests to avoid rate limits
    await new Promise(resolve => setTimeout(resolve, 2000));
  }

  console.log('âœ… AI Testing Complete!');
}

testAI().catch(console.error);